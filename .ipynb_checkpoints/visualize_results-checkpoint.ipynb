{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_u_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acc954043b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_u_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_u_net'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from train_0 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  #'3,2' #'3,2,1,0'\n",
    "\n",
    "def eval_augment(image, mask, index):\n",
    "    pad_image = pad_to_factor(image, factor=16)\n",
    "    \n",
    "#     pad_image = rgb2gray(pad_image)\n",
    "#     pad_image = pad_image[...,np.newaxis]\n",
    "    \n",
    "    input = torch.from_numpy(pad_image.transpose((2,0,1))).float().div(255)\n",
    "    \n",
    "    box, label, instance  = multi_mask_to_annotation(mask)\n",
    "    foreground = (mask!=0).astype(np.float32)\n",
    "    foreground = torch.from_numpy(foreground)\n",
    "\n",
    "    return input, box, label, instance, meta, index, foreground\n",
    "\n",
    "def pad_to_factor(image, factor=16):     \n",
    "    height,width = image.shape[:2]\n",
    "    h = math.ceil(height/factor)*factor                                                                                                                                                                 \n",
    "    w = math.ceil(width/factor)*factor                                                                                                                                                             \n",
    "                                                                                                                                                                                                 \n",
    "    image = cv2.copyMakeBorder(image, top=0, bottom=h-height, left=0, right=w-width,                                                                                                              \n",
    "                               borderType= cv2.BORDER_REFLECT101, value=[0,0,0] )                                                                                                                       \n",
    "                                                                                                                                                                                                          \n",
    "    return image  \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/htang6/remote/gru/workspace/mask-rcnn-resnet50-ver-01.a/results'\n",
    "RESULTS_DIR = '/home/htang6/remote/gru/workspace/crfasrnn_keras/pytorch/results'\n",
    "ROOT_DIR = '/home/htang6/remote/gru/workspace/crfasrnn_keras/pytorch/'\n",
    "\n",
    "out_dir  = RESULTS_DIR + '/crf_box_hitological'\n",
    "initial_checkpoint = RESULTS_DIR + '/crf_box_hitological/checkpoint/000002000_model.pth'\n",
    "# initial_checkpoint = '/media/hdd10tb/zchen/dsb2018/results/mask-rcnn-50-gray500-02/checkpoint/00000999_model.pth'\n",
    "# initial_checkpoint = None\n",
    "cfg = Configuration()\n",
    "# cfg.rpn_train_nms_pre_score_threshold = 0.8 #0.885#0.5\n",
    "# cfg.rpn_test_nms_pre_score_threshold  = 0.8 #0.885#0.5\n",
    "print(cfg)\n",
    "\n",
    "net = UNet(cfg).cuda()\n",
    "\n",
    "if initial_checkpoint is not None:\n",
    "    print('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "    net.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "    \n",
    "net.crf.reset_parameters()\n",
    "print(net.crf.w1)\n",
    "print(net.crf.w2)\n",
    "print(net.crf.w3)\n",
    "print(net.crf.compatibility_matrix)\n",
    "print(net.crf.spatial_ker_weights)\n",
    "print(net.crf.bilateral_ker_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load evaluate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = os.path.join(ROOT_DIR, 'filenames/histological_val.csv')\n",
    "# set_name = os.path.join(ROOT_DIR, 'filenames/fluorescent_train.csv')\n",
    "test_dataset = ScienceDataset(DATA_DIR, set_name, transform=valid_augment, mode='train')\n",
    "test_loader  = DataLoader(\n",
    "                    test_dataset,\n",
    "                    sampler = SequentialSampler(test_dataset),\n",
    "                    batch_size  = 1,\n",
    "                    drop_last   = False,\n",
    "                    num_workers = 4,\n",
    "                    pin_memory  = True,\n",
    "                    collate_fn  = train_collate)\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = os.path.join(ROOT_DIR, 'filenames/histological_train.csv')\n",
    "set_name = os.path.join(ROOT_DIR, 'filenames/fluorescent_val.csv')\n",
    "dataset = ScienceDataset(DATA_DIR, set_name, transform=None, mode='train')\n",
    "\n",
    "aspect = lambda s,x: (s*x**0.5,s/x**0.5)\n",
    "base = 36\n",
    "aspect_ratio = np.array([0.5, 1., 1.5])\n",
    "shapes = [[] for _ in range(len(aspect_ratio))]\n",
    "\n",
    "for i, (image, multi_mask, index) in enumerate(dataset):\n",
    "    boxes, _, _ = multi_mask_to_annotation(multi_mask)\n",
    "    masks = mask_to_instance(multi_mask)\n",
    "    \n",
    "#     plt.imshow(multi_mask)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "#     plt.imshow(masks[2])\n",
    "#     plt.show()\n",
    "    \n",
    "    for j in range(len(boxes)):\n",
    "        box = boxes[j].astype(np.int32)\n",
    "        x0, y0, x1, y1 = box[0], box[1], box[2], box[3]\n",
    "        h, w = y1 - y0, x1 - x0\n",
    "        dist = np.abs(aspect_ratio - float(h) / w) \n",
    "        idx = np.argmin(dist)\n",
    "        shapes[idx].append(masks[j][y0:y1, x0:x1])\n",
    "#         plt.imshow(masks[2][y0:y1, x0:x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "for i, asp in enumerate(aspect_ratio):\n",
    "    for j in range(len(shapes[i])):\n",
    "        tH, tW = aspect(base, asp)\n",
    "        tH, tW = int(tH), int(tW)\n",
    "        shapes[i][j] = scipy.misc.imresize(shapes[i][j], (tH, tW), interp='bilinear')\n",
    "    #     shapes[i] = (shapes[i] > 0.5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "templates = [[] for _ in range(len(aspect_ratio))]\n",
    "\n",
    "for i, asp in enumerate(aspect_ratio):\n",
    "    shapes[i] = np.array(shapes[i])\n",
    "    shapes[i] = np.reshape(shapes[i], (len(shapes[i]), -1))\n",
    "    \n",
    "    tH, tW = aspect(base, asp)\n",
    "    tH, tW = int(tH), int(tW)\n",
    "    n_clusters = 30\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(shapes[i])\n",
    "    templates[i] = np.reshape(kmeans.cluster_centers_, (n_clusters, tH, tW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in kmeans.cluster_centers_:\n",
    "#     plt.imshow(np.reshape(c, (36, 36)))\n",
    "#     plt.show()\n",
    "\n",
    "# for i in range(len(shapes)):\n",
    "#     if kmeans.labels_[i] == 2:\n",
    "#         plt.imshow(np.reshape(shapes[i], (36, 36)))\n",
    "#         plt.show()\n",
    "for i in range(len(templates[1])):\n",
    "    plt.imshow(templates[1][i])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For display, use id = 2\n",
    "id = 5\n",
    "mask_average_precisions = []\n",
    "box_precisions_50  = []\n",
    "r = [0, len(test_loader)]\n",
    "r = [5, 12]\n",
    "test_num  = 0\n",
    "test_loss = np.zeros(5,np.float32)\n",
    "test_acc  = 0\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,4]\n",
    "\n",
    "def get_weights(mask):\n",
    "    w0 = 10\n",
    "    sigma = 5\n",
    "\n",
    "    merged_mask = mask > 0\n",
    "    masks = mask_to_instance(mask)\n",
    "\n",
    "    distances = np.array([ndimage.distance_transform_edt(m == 0) for m in masks])\n",
    "    shortest_dist = np.sort(distances, axis=0)\n",
    "\n",
    "    # distance to the border of the nearest cell\n",
    "    d1 = shortest_dist[0]\n",
    "    # distance to the border of the second nearest cell\n",
    "    d2 = shortest_dist[1] if len(shortest_dist) > 1 else np.zeros(d1.shape)\n",
    "    \n",
    "#     plt.imshow(d1)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.imshow(d2)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    \n",
    "    weight = w0 * np.exp(-(d1 + d2) ** 2 / (2 * sigma ** 2)).astype(np.float32)\n",
    "    weight = 1 + (merged_mask == 0) * weight\n",
    "    return weight\n",
    "\n",
    "def erode_mask(mask):\n",
    "    masks = mask_to_instance(mask)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    for i in range(len(masks)):\n",
    "        masks[i] = cv2.erode(masks[i], kernel, iterations = 1)\n",
    "        \n",
    "    mask = instance_to_multi_mask(masks)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    return mask\n",
    "\n",
    "\n",
    "for i, (inputs, truth_foregrounds, truth_weights, \\\n",
    "        truth_borders, images, truth_masks, indices) in enumerate(test_loader, 0):\n",
    "    #Only display between range[0] and range[1]\n",
    "    if i < r[0] or i >= r[1]:\n",
    "        continue\n",
    "\n",
    "    net.set_mode('test')\n",
    "    net.forward( inputs, truth_masks, shapes)\n",
    "\n",
    "    batch_size,C,H,W = inputs.size()\n",
    "    foregrounds = net.foregrounds[0]\n",
    "    segmentation = F.softmax(foregrounds, 0)\n",
    "    foregrounds = segmentation.cpu().data.numpy()\n",
    "    borders     = net.borders.data.cpu().numpy().squeeze(1)\n",
    "    borders     = np_sigmoid(borders)\n",
    "\n",
    "    truth_foregrounds = truth_foregrounds.data.cpu().numpy()\n",
    "    truth_borders     = truth_borders.data.cpu().numpy()\n",
    "    \n",
    "    truth_foregrounds = truth_foregrounds > 0\n",
    "    \n",
    "    weight = truth_weights.data.cpu().numpy().squeeze()\n",
    "#     weight = get_weights(mask)\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(weight, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    \n",
    "#     distance[distance == 0] = 80\n",
    "#     plt.imshow(-distance[0])\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "    #print('train',batch_size)\n",
    "    for b in range(batch_size): \n",
    "        image            = images[b]\n",
    "        truth_foreground = truth_foregrounds[b]\n",
    "        truth_border     = truth_borders[b]\n",
    "        foreground       = foregrounds[1, :, :]\n",
    "        border           = borders[b]\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(image)\n",
    "        ## draw --------------------------------------------------------------------------\n",
    "        #contour_overlay = multi_mask_to_contour_overlay(truth_mask, image, [255,255,0] )\n",
    "        #color_overlay   = multi_mask_to_color_overlay(mask)\n",
    "\n",
    "        all = np.vstack([\n",
    "            np.hstack([truth_border,truth_foreground]),\n",
    "            np.hstack([border,foreground]),\n",
    "        ])\n",
    "\n",
    "#             image_show_norm('all', all,1)\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(all)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "print('initial_checkpoint  = %s\\n'%(initial_checkpoint))\n",
    "print('test_acc  = %0.5f\\n'%(test_acc))\n",
    "print('test_loss = %0.5f\\n'%(test_loss[0]))\n",
    "print('test_num  = %d\\n'%(test_num))\n",
    "print('\\n')\n",
    "\n",
    "mask_average_precisions = np.array(mask_average_precisions)\n",
    "box_precisions_50 = np.array(box_precisions_50)\n",
    "print('-------------\\n')\n",
    "print('mask_average_precision = %0.5f\\n'%mask_average_precisions.mean())\n",
    "print('box_precision@0.5 = %0.5f\\n'%box_precisions_50.mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mask = truth_masks[0]\n",
    "boxes, _, _ = multi_mask_to_annotation(mask)\n",
    "unary = get_unary(segmentation.unsqueeze(0), boxes, templates, 0.1, 0.4, 0.5)\n",
    "# unary = segmentation.unsqueeze(0)\n",
    "# unary = torch.log(unary)\n",
    "\n",
    "# crf = CrfRnnLayer(2, 5, 160., 3., 3.).cuda()\n",
    "crf = net.crf\n",
    "net.crf.spatial_ker_weights[0] = 1.\n",
    "net.crf.bilateral_ker_weights[0] = 1.\n",
    "net.crf.w1[0] = 0.0\n",
    "net.crf.w3[0] = 0.1\n",
    "print(net.crf.w1)\n",
    "print(net.crf.w2)\n",
    "print(net.crf.w3)\n",
    "print(net.crf.compatibility_matrix)\n",
    "print(net.crf.spatial_ker_weights)\n",
    "print(net.crf.bilateral_ker_weights)\n",
    "# crf.reset_parameters()\n",
    "output = crf(unary, inputs, None)\n",
    "\n",
    "# print(output[:,0,0])\n",
    "output = F.softmax(output, 0)\n",
    "\n",
    "num_class, H, W = output.shape\n",
    "output = output.view(num_class, -1)\n",
    "value, classes = torch.max(output, dim=0)\n",
    "classes = classes.view(H, W)\n",
    "print(classes.shape)\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(classes.detach())\n",
    "plt.title('Crf prediction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(foreground)\n",
    "plt.title('Unet prediction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow(truth_foreground)\n",
    "plt.title('GT')\n",
    "plt.show()\n",
    "print(crf.compatibility_matrix)\n",
    "\n",
    "plt.imshow(foreground > 0.5)\n",
    "plt.title('Unet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = truth_masks[0]\n",
    "boxes, _, _ = multi_mask_to_annotation(mask)\n",
    "plt.imshow(mask)\n",
    "plt.colorbar()\n",
    "\n",
    "crf_out = classes.cpu().data.numpy()\n",
    "pred_instance = mask_to_instance(crf_out).astype(np.int32)\n",
    "gt_instance = mask_to_instance(mask).astype(np.int32)\n",
    "\n",
    "overlap = torch.zeros(len(gt_instance), len(pred_instance))\n",
    "for i in range(len(gt_instance)):\n",
    "    for j in range(len(pred_instance)):\n",
    "        overlap[i, j] = np.bitwise_and(gt_instance[i], pred_instance[j]).sum() / np.bitwise_or(gt_instance[i], pred_instance[j]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(unary[0])):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(unary[0][i].detach())\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(output[i].view(H, W).detach())\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFG:\n",
    "    def __init__(self,graph):\n",
    "         \n",
    "        # residual graph\n",
    "        self.graph = graph \n",
    "        self.ppl = len(graph)\n",
    "        self.jobs = len(graph[0])\n",
    " \n",
    "    # A DFS based recursive function\n",
    "    # that returns true if a matching \n",
    "    # for vertex u is possible\n",
    "    def bpm(self, u, matchR, seen):\n",
    " \n",
    "        # Try every job one by one\n",
    "        for v in range(self.jobs):\n",
    " \n",
    "            # If applicant u is interested \n",
    "            # in job v and v is not seen\n",
    "            if self.graph[u][v] and seen[v] == False:\n",
    "                 \n",
    "                # Mark v as visited\n",
    "                seen[v] = True\n",
    " \n",
    "                '''If job 'v' is not assigned to\n",
    "                   an applicant OR previously assigned \n",
    "                   applicant for job v (which is matchR[v]) \n",
    "                   has an alternate job available. \n",
    "                   Since v is marked as visited in the \n",
    "                   above line, matchR[v]  in the following\n",
    "                   recursive call will not get job 'v' again'''\n",
    "                if matchR[v] == -1 or self.bpm(matchR[v], \n",
    "                                               matchR, seen):\n",
    "                    matchR[v] = u\n",
    "                    return True\n",
    "        return False\n",
    " \n",
    "    # Returns maximum number of matching \n",
    "    def maxBPM(self):\n",
    "        '''An array to keep track of the \n",
    "           applicants assigned to jobs. \n",
    "           The value of matchR[i] is the \n",
    "           applicant number assigned to job i, \n",
    "           the value -1 indicates nobody is assigned.'''\n",
    "        matchR = [-1] * self.jobs\n",
    "         \n",
    "        # Count of jobs assigned to applicants\n",
    "        result = 0\n",
    "        for i in range(self.ppl):\n",
    "             \n",
    "            # Mark all jobs as not seen for next applicant.\n",
    "            seen = [False] * self.jobs\n",
    "             \n",
    "            # Find if the applicant 'u' can get a job\n",
    "            if self.bpm(i, matchR, seen):\n",
    "                result += 1\n",
    "        return matchR\n",
    "    \n",
    "g = GFG(overlap.t())\n",
    "match = g.maxBPM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = np.zeros((H, W))\n",
    "for i in range(len(gt_instance)):\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(gt_instance[i])\n",
    "    \n",
    "#     plt.subplot(122)\n",
    "#     if match[i] != -1:\n",
    "#         plt.imshow(pred_instance[match[i]])\n",
    "#     plt.show()\n",
    "    target[gt_instance[i] > 0] = match[i]\n",
    "    \n",
    "plt.subplot(121)\n",
    "plt.imshow(target)\n",
    "plt.title('matched ground truth')\n",
    "plt.subplot(122)\n",
    "plt.imshow(classes)\n",
    "plt.title('prediction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
